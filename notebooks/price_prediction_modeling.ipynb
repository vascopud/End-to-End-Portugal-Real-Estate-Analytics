{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "20163830",
            "metadata": {},
            "source": [
                "# Price Prediction Modeling\n",
                "\n",
                "In this notebook, we build and evaluate machine learning models to predict property prices in Portugal based on location, area, and typology."
            ]
        },
        {
            "cell_type": "code",
            "id": "ad8e606d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import psycopg2\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Preprocessing & Metrics\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "import category_encoders as ce\n",
                "\n",
                "# Models\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from xgboost import XGBRegressor\n",
                "\n",
                "load_dotenv(\"../.env\")\n",
                "sns.set_theme(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3069dce7",
            "metadata": {},
            "source": [
                "## 1. Data Loading & Initial Cleaning"
            ]
        },
        {
            "cell_type": "code",
            "id": "62e55b77",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_db_connection():\n",
                "    return psycopg2.connect(\n",
                "        host=os.getenv('DB_HOST', 'localhost'),\n",
                "        database=os.getenv('DB_NAME'),\n",
                "        user=os.getenv('DB_USER'),\n",
                "        password=os.getenv('DB_PASSWORD')\n",
                "    )\n",
                "\n",
                "conn = get_db_connection()\n",
                "query = \"SELECT price, distrito, concelho, freguesia, area_m2, room_count FROM properties\"\n",
                "df = pd.read_sql(query, conn)\n",
                "conn.close()\n",
                "\n",
                "# Apply basic filters identified in EDA\n",
                "df = df[(df['price'] > 0) & (df['area_m2'] > 0)]\n",
                "\n",
                "def remove_outliers(df, column):\n",
                "    Q1 = df[column].quantile(0.25)\n",
                "    Q3 = df[column].quantile(0.75)\n",
                "    IQR = Q3 - Q1\n",
                "    return df[(df[column] >= Q1 - 1.5*IQR) & (df[column] <= Q3 + 1.5*IQR)]\n",
                "\n",
                "df_clean = remove_outliers(df, 'price')\n",
                "df_clean = remove_outliers(df_clean, 'area_m2')\n",
                "\n",
                "print(f\"Dataset size after cleaning: {len(df_clean)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "528ad303",
            "metadata": {},
            "source": [
                "## 2. Train-Validation-Test Split\n",
                "\n",
                "We split the data into 70% training, 15% validation (for tuning), and 15% testing (final evaluation)."
            ]
        },
        {
            "cell_type": "code",
            "id": "987299e0",
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df_clean.drop('price', axis=1)\n",
                "y = df_clean['price']\n",
                "\n",
                "# First split: train + val vs test\n",
                "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
                "\n",
                "# Second split: train vs val\n",
                "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, random_state=42) # 0.1765 * 0.85 approx 0.15\n",
                "\n",
                "print(f\"Train size: {len(X_train)}\")\n",
                "print(f\"Val size: {len(X_val)}\")\n",
                "print(f\"Test size: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e7ec67f5",
            "metadata": {},
            "source": [
                "## 3. Preprocessing Pipeline\n",
                "\n",
                "- **Numeric**: Scale `area_m2` and impute missing `room_count`.\n",
                "- **High Cardinality Cat**: `TargetEncoder` for `freguesia` and `concelho`.\n",
                "- **Low Cardinality Cat**: `OneHotEncoder` for `distrito`."
            ]
        },
        {
            "cell_type": "code",
            "id": "3ef2867c",
            "metadata": {},
            "outputs": [],
            "source": [
                "numeric_features = ['area_m2', 'room_count']\n",
                "target_encoded_features = ['freguesia', 'concelho']\n",
                "onehot_features = ['distrito']\n",
                "\n",
                "numeric_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='median')),\n",
                "    ('scaler', StandardScaler())\n",
                "])\n",
                "\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', numeric_transformer, numeric_features),\n",
                "        ('target', ce.TargetEncoder(), target_encoded_features),\n",
                "        ('onehot', OneHotEncoder(handle_unknown='ignore'), onehot_features)\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a958dde1",
            "metadata": {},
            "source": [
                "## 4. Model Benchmarking (Default Params)\n",
                "\n",
                "Evaluating Linear Regression, Random Forest, and XGBoost with default parameters."
            ]
        },
        {
            "cell_type": "code",
            "id": "8cfc0a51",
            "metadata": {},
            "outputs": [],
            "source": [
                "models = {\n",
                "    \"Linear Regression\": LinearRegression(),\n",
                "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
                "    \"XGBoost\": XGBRegressor(random_state=42)\n",
                "}\n",
                "\n",
                "results = []\n",
                "\n",
                "for name, model in models.items():\n",
                "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                          ('regressor', model)])\n",
                "    \n",
                "    clf.fit(X_train, y_train)\n",
                "    y_pred = clf.predict(X_val)\n",
                "    \n",
                "    mae = mean_absolute_error(y_val, y_pred)\n",
                "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
                "    r2 = r2_score(y_val, y_pred)\n",
                "    \n",
                "    results.append({\"Model\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2})\n",
                "    print(f\"{name} - R2: {r2:.4f}\")\n",
                "\n",
                "pd.DataFrame(results)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f8d2c33e",
            "metadata": {},
            "source": [
                "## 5. Hyperparameter Tuning\n",
                "\n",
                "We use `RandomizedSearchCV` for efficiency given the large parameter space."
            ]
        },
        {
            "cell_type": "code",
            "id": "88c1d816",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Random Forest Tuning\n",
                "rf_param_grid = {\n",
                "    'regressor__n_estimators': [100, 200, 500],\n",
                "    'regressor__max_depth': [10, 20, 30, None],\n",
                "    'regressor__min_samples_split': [2, 5, 10],\n",
                "    'regressor__min_samples_leaf': [1, 2, 4],\n",
                "    'regressor__bootstrap': [True, False]\n",
                "}\n",
                "\n",
                "rf_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                          ('regressor', RandomForestRegressor(random_state=42))])\n",
                "\n",
                "rf_search = RandomizedSearchCV(rf_pipe, rf_param_grid, n_iter=15, cv=3, scoring='r2', n_jobs=-1, random_state=42)\n",
                "rf_search.fit(X_train, y_train)\n",
                "\n",
                "print(f\"Best RF Params: {rf_search.best_params_}\")\n",
                "print(f\"Best RF Val R2: {rf_search.best_score_:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "id": "xgb_tuning",
            "metadata": {},
            "outputs": [],
            "source": [
                "# XGBoost Tuning\n",
                "xgb_param_grid = {\n",
                "    'regressor__n_estimators': [100, 200, 500],\n",
                "    'regressor__max_depth': [3, 6, 10],\n",
                "    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
                "    'regressor__subsample': [0.7, 0.8, 1.0],\n",
                "    'regressor__colsample_bytree': [0.7, 0.8, 1.0]\n",
                "}\n",
                "\n",
                "xgb_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                           ('regressor', XGBRegressor(random_state=42))])\n",
                "\n",
                "xgb_search = RandomizedSearchCV(xgb_pipe, xgb_param_grid, n_iter=15, cv=3, scoring='r2', n_jobs=-1, random_state=42)\n",
                "xgb_search.fit(X_train, y_train)\n",
                "\n",
                "print(f\"Best XGB Params: {xgb_search.best_params_}\")\n",
                "print(f\"Best XGB Val R2: {xgb_search.best_score_:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "50f6a7f5",
            "metadata": {},
            "source": [
                "## 6. Final Evaluation & Feature Importance\n",
                "\n",
                "Testing the overall best model on the unseen Test set."
            ]
        },
        {
            "cell_type": "code",
            "id": "aeb0e846",
            "metadata": {},
            "outputs": [],
            "source": [
                "best_rf_score = rf_search.best_score_\n",
                "best_xgb_score = xgb_search.best_score_\n",
                "\n",
                "if best_rf_score > best_xgb_score:\n",
                "    best_model = rf_search.best_estimator_\n",
                "    print(\"Best model found: Random Forest\")\n",
                "else:\n",
                "    best_model = xgb_search.best_estimator_\n",
                "    print(\"Best model found: XGBoost\")\n",
                "\n",
                "y_test_pred = best_model.predict(X_test)\n",
                "\n",
                "print(\"--- Final Test Set Metrics ---\")\n",
                "print(f\"MAE:  {mean_absolute_error(y_test, y_test_pred):.2f}\")\n",
                "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.2f}\")\n",
                "print(f\"R2:   {r2_score(y_test, y_test_pred):.4f}\")\n",
                "\n",
                "# Feature Importance\n",
                "importances = best_model.named_steps['regressor'].feature_importances_\n",
                "# Get feature names from preprocessor\n",
                "cat_features = list(best_model.named_steps['preprocessor'].transformers_[2][1].get_feature_names_out())\n",
                "feature_names = numeric_features + target_encoded_features + cat_features\n",
                "\n",
                "feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(15)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "feat_imp.plot(kind='barh', color='teal')\n",
                "plt.title('Top 15 Feature Importances (Best Model)')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}